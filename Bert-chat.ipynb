{"cells":[{"cell_type":"code","source":["# Instalación de librerías\n","!pip install transformers torch scikit-learn nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDBZk1SJ6tZG","executionInfo":{"status":"ok","timestamp":1737804169171,"user_tz":-60,"elapsed":11794,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"3867332b-cfd2-4186-a18d-d6327b77515e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"]}]},{"cell_type":"code","source":["# Importaciones\n","import pandas as pd\n","import numpy as np\n","import torch\n","import nltk\n","from google.colab import drive\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import SnowballStemmer\n","from nltk.corpus import stopwords\n","import re"],"metadata":{"id":"DqJg6CBp6xD1","executionInfo":{"status":"ok","timestamp":1737804214233,"user_tz":-60,"elapsed":45072,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Montar Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3CuXUL_69Ro","executionInfo":{"status":"ok","timestamp":1737804233193,"user_tz":-60,"elapsed":18968,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"f96224f1-3ce1-4acc-f87a-c1dbd48b0359"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Descargar recursos NLTK\n","#nltk.download('punkt')\n","#nltk.download('stopwords')\n","nltk.download('all')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-52yGGuV7EY_","executionInfo":{"status":"ok","timestamp":1737804290874,"user_tz":-60,"elapsed":57688,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"ae27d33a-a0a6-4a8d-f4c0-3ee442ccf8c4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package tagsets_json to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets_json.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["class ChatbotAvanzado:\n","    def __init__(self, ruta_dataset):\n","        # Cargar dataset desde Drive\n","        self.df = pd.read_csv(ruta_dataset)\n","\n","        # Configuración de procesamiento\n","        self.stemmer = SnowballStemmer('spanish')  #Para reducir palabras a su raíz\n","        self.stop_words = set(stopwords.words('spanish')) #Palabras comunes que se ignoran\n","\n","        # Cargar modelo de lenguaje \"BERT multilingüe pre-entrenado para procesar lenguaje natural\".\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","        self.model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","        # Preprocesar datos\n","        self.preprocesar_datos()\n","\n","        # Vectorización\n","        self.vectorizador = TfidfVectorizer(\n","            stop_words=list(self.stop_words),\n","            max_features=5000\n","        )\n","        self.X = self.vectorizador.fit_transform(self.df['texto_limpio'])\n","\n","        # Contexto de conversación\n","        self.contexto = []\n","\n","    def preprocesar_texto(self, texto): #Este método limpia y preprocesa el texto\n","        \"\"\"Preprocesar texto\"\"\"\n","        texto = str(texto).lower()\n","        texto = re.sub(r'[^a-záéíóúñ\\s]', '', texto)\n","        tokens = word_tokenize(texto)\n","        tokens = [self.stemmer.stem(word) for word in tokens if word not in self.stop_words]\n","        return ' '.join(tokens)\n","\n","    def preprocesar_datos(self): #Aplica el preprocesamiento a la columna 'pregunta' del dataset.\n","        \"\"\"Preprocesar columnas del dataset\"\"\"\n","        self.df['texto_limpio'] = self.df['pregunta'].apply(self.preprocesar_texto)\n","\n","    def obtener_embedding_bert(self, texto): #Representaciones vectoriales del texto.\n","        \"\"\"Obtener embedding con BERT\"\"\"\n","        inputs = self.tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n","        with torch.no_grad():\n","            outputs = self.model(**inputs)\n","        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n","\n","    def buscar_respuesta_semantica(self, consulta): #Busca la respuesta más relevante combinando similitud TF-IDF y similitud basada en BERT.\n","        \"\"\"Buscar respuesta usando similitud semántica\"\"\"\n","        consulta_limpia = self.preprocesar_texto(consulta)\n","\n","        # Vectorización TF-IDF\n","        consulta_vectorizada = self.vectorizador.transform([consulta_limpia])\n","        similitudes_tfidf = cosine_similarity(consulta_vectorizada, self.X)[0]\n","\n","        # Embedding BERT para similitud semántica\n","        consulta_embedding = self.obtener_embedding_bert(consulta)\n","\n","        # Combinar métodos de similitud\n","        indices_top = np.argsort(similitudes_tfidf)[::-1][:5]\n","\n","        mejores_respuestas = []\n","        for idx in indices_top:\n","            respuesta_candidata = self.df.iloc[idx]\n","            similitud_bert = cosine_similarity(\n","                [consulta_embedding],\n","                [self.obtener_embedding_bert(respuesta_candidata['pregunta'])]\n","            )[0][0]\n","\n","            mejores_respuestas.append({\n","                'respuesta': respuesta_candidata['respuesta'],\n","                'similitud_tfidf': similitudes_tfidf[idx],\n","                'similitud_bert': similitud_bert\n","            })\n","\n","        # Ordenar por una combinación de similitudes\n","        mejores_respuestas.sort(key=lambda x: (x['similitud_tfidf'] + x['similitud_bert']), reverse=True)\n","\n","        return mejores_respuestas[0]['respuesta'] if mejores_respuestas else \"Lo siento, no puedo encontrar una respuesta adecuada.\"\n","\n","    def manejar_contexto(self, consulta): #Mantiene un contexto de las últimas 3 consultas y busca una respuesta basada en este contexto.\n","        \"\"\"Manejar contexto de conversación\"\"\"\n","        self.contexto.append(consulta)\n","        if len(self.contexto) > 3:\n","            self.contexto.pop(0)\n","\n","        return self.buscar_respuesta_semantica(consulta)\n","\n","    def iniciar_chat(self): #Inicia una interfaz de chat en la consola, permitiendo al usuario interactuar con el chatbot.\n","        \"\"\"Iniciar chatbot interactivo\"\"\"\n","        print(\"🤖 Chatbot de Servicio al Cliente\")\n","        print(\"Escribe 'salir' para terminar la conversación\\n\")\n","\n","        while True:\n","            consulta = input(\"👤 Tú: \")\n","\n","            if consulta.lower() == 'salir':\n","                print(\"🤖 Gracias por usar nuestro servicio. ¡Hasta luego!\")\n","                break\n","\n","            respuesta = self.manejar_contexto(consulta)\n","            print(f\"🤖 Respuesta: {respuesta}\\n\")\n","\n","# Ruta del dataset en Google Drive\n","RUTA_DATASET = '/content/drive/My Drive/LLM/datos_chatbot_soporte_tecnico.csv'\n"],"metadata":{"id":"DIIa6wGu6hdx","executionInfo":{"status":"ok","timestamp":1737804294015,"user_tz":-60,"elapsed":184,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Inicializar y ejecutar chatbot\n","chatbot = ChatbotAvanzado(RUTA_DATASET)\n","chatbot.iniciar_chat()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydmAEav68y84","executionInfo":{"status":"ok","timestamp":1737805835696,"user_tz":-60,"elapsed":848617,"user":{"displayName":"Gonzalo Caceres","userId":"01178933759601003683"}},"outputId":"5f4e4a98-00e9-4730-f276-319d789dc14c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["🤖 Chatbot de Servicio al Cliente\n","Escribe 'salir' para terminar la conversación\n","\n","👤 Tú: tipos de baterias\n","🤖 Respuesta: Ion-Litio más comunes, Polímero de Litio más delgadas, Níquel menos eficientes.\n","\n","👤 Tú: deseo saber las caracteristicas del modelo X\n","🤖 Respuesta: El modelo X cuenta con una pantalla de 6.5 pulgadas, procesador Snapdragon 888, 8 GB de RAM, y una batería de 4500 mAh.\n","\n","👤 Tú: ¿Cómo extender vida batería laptop?\n","🤖 Respuesta: Mantén carga entre 20-80%, evita temperaturas extremas, usa modo ahorro energía.\n","\n","👤 Tú: Mi smartphone no enciende\n","🤖 Respuesta: Intenta mantener presionado el botón de encendido durante 10 segundos. Si no responde, conecta el cargador y espera unos minutos antes de intentar encenderlo nuevamente.\n","\n","👤 Tú: sigue sin encender, que hago?\n","🤖 Respuesta: Si presionar el botón de encendido no funciona, conecta el smartphone al cargador original y déjalo cargando durante al menos 15 minutos antes de intentar encenderlo nuevamente.\n","\n","👤 Tú: ¿Cuál es la garantía de mi laptop?\n","🤖 Respuesta: La garantía cubre defectos en materiales y mano de obra, pero no cubre daños causados por mal uso o accidentes.\n","\n","👤 Tú: ¿me puedes decir si la cámara de la laptop modelo Y incluye micrófono?\n","🤖 Respuesta: Sí, la cámara HD de 720p de la laptop modelo Y incluye un micrófono incorporado.\n","\n","👤 Tú: que producto tienes resistente al agua?\n","🤖 Respuesta: Sí, el producto Z tiene una clasificación IP67, lo que significa que es resistente al agua hasta 1 metro durante 30 minutos.\n","\n","👤 Tú: Mi smartphone no enciende ni responde a la carga. ¿Qué debo hacer?\n","🤖 Respuesta: Si tu smartphone no enciende ni responde a la carga, intenta realizar un reinicio forzado manteniendo presionados los botones de encendido y volumen durante 10-15 segundos. Si aún no funciona, contacta con nuestro soporte técnico.\n","\n","👤 Tú: sabes si es normal que la laptop se caliente?\n","🤖 Respuesta: Un poco de calor es normal durante el uso intensivo, pero si se calienta excesivamente, asegúrate de que las ventilaciones no estén bloqueadas y considera usar un soporte refrigerante.\n","\n","👤 Tú: como puedo reducir el calentamiento\n","🤖 Respuesta: Para reducir el calentamiento, asegúrate de que las ventilaciones de la laptop no estén bloqueadas, usa la laptop en superficies duras y planas, limpia regularmente los ventiladores de polvo, y considera usar un soporte refrigerante.\n","\n","👤 Tú: a que temperatura deberia preocuparme?\n","🤖 Respuesta: Aunque las laptops pueden calentarse durante el uso intensivo, si notas que está demasiado caliente para tocar cómodamente (generalmente por encima de los 70°C), deberías apagarla y dejarla enfriar. Si el problema persiste, contacta con soporte técnico.\n","\n","👤 Tú: ¿Qué tipo de defectos están cubiertos por la garantía del producto?\n","🤖 Respuesta: La garantía del producto V cubre defectos en materiales y mano de obra que afecten el funcionamiento normal del dispositivo. Esto incluye problemas con componentes internos, pantalla o batería que no sean resultado de daños externos o mal uso.\n","\n","👤 Tú: como puedo reclamar la garantia?\n","🤖 Respuesta: Para reclamar la garantía, necesitas presentar el recibo original y contactar a nuestro servicio al cliente a través del sitio web o por teléfono.\n","\n","👤 Tú: y que documentos necesito?\n","🤖 Respuesta: Para reclamar la garantía, necesitas presentar el recibo original de compra o factura que muestre la fecha de adquisición del producto. También es útil tener a mano el número de serie del dispositivo.\n","\n","👤 Tú: salir\n","🤖 Gracias por usar nuestro servicio. ¡Hasta luego!\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}