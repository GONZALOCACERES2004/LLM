{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py guarda todo el script del chatbot en un archivo app.py que luego puede ser ejecutado independientemente del notebook.\n",
        "%%writefile app.py\n",
        "import streamlit as st  # Crear interfaz web interactiva\n",
        "import pandas as pd # Manejo de datasets\n",
        "import numpy as np  # Operaciones numéricas\n",
        "import torch # Procesamiento con redes neuronales\n",
        "import nltk # Procesamiento de lenguaje natural\n",
        "import pickle # Serializar y deserializar objetos (guardar/cargar modelo)\n",
        "import os # Operaciones con sistema de archivos\n",
        "from google.colab import drive # Montar y acceder a archivos en Google Drive\n",
        "from transformers import AutoTokenizer, AutoModel  # Modelos de lenguaje BERT\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #  Vectorización\n",
        "from sklearn.metrics.pairwise import cosine_similarity # Calcular similitud semántica entre textos\n",
        "from nltk.tokenize import word_tokenize # Dividir texto en tokens\n",
        "from nltk.stem import SnowballStemmer # Reducir palabras a su raíz (stemming) en español\n",
        "from nltk.corpus import stopwords # Obtener lista de palabras vacías (stopwords) en español\n",
        "import re # Limpiar y manipular texto\n",
        "from datetime import datetime # Manejar fechas y timestamps\n",
        "\n",
        "# Descargar recursos NLTK\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('all')\n",
        "\n",
        "class ChatbotAvanzado:\n",
        "    def __init__(self, ruta_dataset, ruta_modelo=None):\n",
        "        # Inicializar stemmer y stop_words siempre\n",
        "        self.stemmer = SnowballStemmer('spanish')\n",
        "        self.stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "        # Carga o Creación de Modelo\n",
        "        if ruta_modelo and self.cargar_modelo(ruta_modelo):\n",
        "            st.success(\"Modelo cargado exitosamente.\")\n",
        "        else:\n",
        "            st.info(\"Creando nuevo modelo...\")\n",
        "            self.df = pd.read_csv(ruta_dataset)\n",
        "\n",
        "            # Preprocesar datos\n",
        "            self.preprocesar_datos()\n",
        "\n",
        "            # Vectorización (Prepara datos para cálculo de similitud semántica)\n",
        "            self.vectorizador = TfidfVectorizer(\n",
        "                stop_words=list(self.stop_words),\n",
        "                max_features=5000\n",
        "            )\n",
        "            self.X = self.vectorizador.fit_transform(self.df['texto_limpio'])\n",
        "\n",
        "        # Cargar modelo de lenguaje (siempre se carga porque no lo guardamos)\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "        # Contexto de conversación\n",
        "        self.contexto = []\n",
        "\n",
        "        # Nuevas variables para almacenar interacciones\n",
        "        self.nuevas_interacciones = []\n",
        "        self.umbral_actualizacion = 10  # Número de interacciones antes de actualizar\n",
        "\n",
        "    def preprocesar_texto(self, texto):\n",
        "        \"\"\"Preprocesar texto\"\"\"\n",
        "        texto = str(texto).lower()\n",
        "        texto = re.sub(r'[^a-záéíóúñ\\s]', '', texto)\n",
        "        tokens = word_tokenize(texto)\n",
        "        tokens = [self.stemmer.stem(word) for word in tokens if word not in self.stop_words]\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    def preprocesar_datos(self):\n",
        "        \"\"\"Preprocesar columnas del dataset\"\"\"\n",
        "        self.df['texto_limpio'] = self.df['pregunta'].apply(self.preprocesar_texto)\n",
        "\n",
        "    def obtener_embedding_bert(self, texto):\n",
        "        \"\"\"Obtener embedding con BERT\"\"\"\n",
        "        inputs = self.tokenizer(texto, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "    def buscar_respuesta_semantica(self, consulta):\n",
        "      \"\"\"Buscar respuesta usando similitud semántica\"\"\"\n",
        "      consulta_limpia = self.preprocesar_texto(consulta)\n",
        "\n",
        "      # Vectorización TF-IDF\n",
        "      consulta_vectorizada = self.vectorizador.transform([consulta_limpia])\n",
        "      similitudes_tfidf = cosine_similarity(consulta_vectorizada, self.X)[0]\n",
        "\n",
        "      # Embedding BERT para similitud semántica\n",
        "      consulta_embedding = self.obtener_embedding_bert(consulta)\n",
        "\n",
        "      # Combinar métodos de similitud\n",
        "      indices_top = np.argsort(similitudes_tfidf)[::-1][:5]\n",
        "\n",
        "      mejores_respuestas = []\n",
        "      for idx in indices_top:\n",
        "          respuesta_candidata = self.df.iloc[idx]\n",
        "          similitud_bert = cosine_similarity(\n",
        "              [consulta_embedding],\n",
        "              [self.obtener_embedding_bert(respuesta_candidata['pregunta'])]\n",
        "          )[0][0]\n",
        "\n",
        "          mejores_respuestas.append({\n",
        "              'respuesta': respuesta_candidata['respuesta'],\n",
        "              'similitud_tfidf': similitudes_tfidf[idx],\n",
        "              'similitud_bert': similitud_bert\n",
        "          })\n",
        "\n",
        "      # Ordenar por una combinación de similitudes\n",
        "      mejores_respuestas.sort(key=lambda x: (x['similitud_tfidf'] + x['similitud_bert']), reverse=True)\n",
        "\n",
        "      umbral_confianza = 1.0  # Definir un umbral de confianza\n",
        "      if mejores_respuestas and (mejores_respuestas[0]['similitud_tfidf'] + mejores_respuestas[0]['similitud_bert']) > umbral_confianza:\n",
        "          mejor_respuesta = mejores_respuestas[0]['respuesta']\n",
        "          mejor_similitud = mejores_respuestas[0]['similitud_tfidf'] + mejores_respuestas[0]['similitud_bert']\n",
        "      else:\n",
        "          mejor_respuesta = \"Lo siento, no tengo una respuesta confiable para esa pregunta.\"\n",
        "          mejor_similitud = mejores_respuestas[0]['similitud_tfidf'] + mejores_respuestas[0]['similitud_bert']\n",
        "\n",
        "      return mejor_respuesta, mejor_similitud\n",
        "    def manejar_contexto(self, consulta):\n",
        "        \"\"\"Manejar contexto de conversación\"\"\"\n",
        "        self.contexto.append(consulta)\n",
        "        if len(self.contexto) > 3:\n",
        "            self.contexto.pop(0)\n",
        "\n",
        "        return self.buscar_respuesta_semantica(consulta)\n",
        "\n",
        "    def almacenar_interaccion(self, pregunta, respuesta, retroalimentacion):\n",
        "        \"\"\"Almacena una nueva interacción\"\"\"\n",
        "        self.nuevas_interacciones.append({\n",
        "            'pregunta': pregunta,\n",
        "            'respuesta': respuesta,\n",
        "            'retroalimentacion': retroalimentacion,\n",
        "            'fecha': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        })\n",
        "\n",
        "    def actualizar_modelo(self):\n",
        "        \"\"\"Actualiza el modelo con las nuevas interacciones\"\"\"\n",
        "        if len(self.nuevas_interacciones) > 0:\n",
        "            # Convertir interacciones a DataFrame\n",
        "            nuevos_datos = pd.DataFrame(self.nuevas_interacciones)\n",
        "            # Concatenar interacciones\n",
        "            self.df = pd.concat([self.df, nuevos_datos[['pregunta', 'respuesta']]], ignore_index=True)\n",
        "            # Reprocesar y actualizar vectorización\n",
        "            self.preprocesar_datos()\n",
        "            self.X = self.vectorizador.fit_transform(self.df['texto_limpio'])\n",
        "            # Reiniciar interacciones\n",
        "            self.nuevas_interacciones = []\n",
        "            st.success(\"Modelo actualizado con nuevas interacciones.\")\n",
        "\n",
        "    def guardar_modelo(self, ruta_guardado):\n",
        "        \"\"\"Guarda el modelo y los datos procesados\"\"\"\n",
        "        self.actualizar_modelo()  # Incluir las últimas interacciones\n",
        "        datos_guardado = {\n",
        "            'vectorizador': self.vectorizador,\n",
        "            'X': self.X,\n",
        "            'df': self.df,\n",
        "            'nuevas_interacciones': self.nuevas_interacciones\n",
        "        }\n",
        "        with open(ruta_guardado, 'wb') as archivo:\n",
        "            pickle.dump(datos_guardado, archivo)\n",
        "        st.success(f\"Modelo guardado en {ruta_guardado}\")\n",
        "\n",
        "    def cargar_modelo(self, ruta_carga):\n",
        "        \"\"\"Carga el modelo y los datos procesados\"\"\"\n",
        "        if os.path.exists(ruta_carga):\n",
        "            with open(ruta_carga, 'rb') as archivo:\n",
        "                datos_cargados = pickle.load(archivo)\n",
        "            self.vectorizador = datos_cargados['vectorizador']\n",
        "            self.X = datos_cargados['X']\n",
        "            self.df = datos_cargados['df']\n",
        "            self.nuevas_interacciones = datos_cargados.get('nuevas_interacciones', [])\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    st.title(\"🤖 Chatbot de Asistencia al Cliente - Gonzalo Cáceres\")\n",
        "    st.write(\"Bienvenido al asistente de soporte técnico. ¿En qué puedo ayudarte hoy?\")\n",
        "\n",
        "    # Rutas de archivos\n",
        "    RUTA_DATASET = '/content/drive/My Drive/LLM/datos_chatbot_soporte_tecnico.csv'\n",
        "    RUTA_MODELO = '/content/drive/My Drive/LLM/modelo_chatbot.pkl'\n",
        "\n",
        "    # Inicializar chatbot\n",
        "    if 'chatbot' not in st.session_state:\n",
        "        st.session_state.chatbot = ChatbotAvanzado(RUTA_DATASET, RUTA_MODELO)\n",
        "\n",
        "    # Inicializar historial de mensajes\n",
        "    if 'messages' not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "\n",
        "    # Mostrar historial de mensajes\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Input del usuario\n",
        "    if prompt := st.chat_input(\"Escribe tu pregunta aquí\"):\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        respuesta, confianza = st.session_state.chatbot.manejar_contexto(prompt)\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": respuesta})\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.markdown(respuesta)\n",
        "            st.markdown(f\"Confianza: {confianza:.2f}\")\n",
        "\n",
        "        # Retroalimentación del usuario\n",
        "        retroalimentacion = st.slider(\"Califica la utilidad de la respuesta\", 1, 5, 3)\n",
        "        st.session_state.chatbot.almacenar_interaccion(prompt, respuesta, retroalimentacion)\n",
        "\n",
        "        # Actualizar el modelo si se alcanza el umbral\n",
        "        if len(st.session_state.chatbot.nuevas_interacciones) >= st.session_state.chatbot.umbral_actualizacion:\n",
        "            st.session_state.chatbot.actualizar_modelo()\n",
        "            st.session_state.chatbot.guardar_modelo(RUTA_MODELO)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "DIIa6wGu6hdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc2be93-ab8c-498d-8f13-693e297665a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de librerías\n",
        "!pip install streamlit transformers torch scikit-learn pandas nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDBZk1SJ6tZG",
        "outputId": "ac8b1244-e0d2-4103-b347-cec50c5be1a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3CuXUL_69Ro",
        "outputId": "39c558dd-367d-410f-a5eb-4f59d3bc8ea6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5BH9QvdvS1A",
        "outputId": "1f818f20-2e71-431f-b347-7384bfa34f98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.80.175.23"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ_g45fwpryV",
        "outputId": "1081a883-af3a-4c54-959f-dd50dc314f71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://smart-lights-notice.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}